{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def download_and_analyze(video_url):\n",
    "  \"\"\"Downloads and analyzes a video, returning video capture object, FPS, and frame count.\"\"\"\n",
    "  # Download video using libraries like urllib\n",
    "  video = cv2.VideoCapture(video_url)\n",
    "  fps = video.get(cv2.CAP_PROP_FPS)  #fame per second\n",
    "  frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  return video, fps, frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predefined_clips(filepath):\n",
    "  \"\"\"Reads pre-determined clip timings from a file (replace with your logic).\"\"\"\n",
    "  clips = []\n",
    "  with open(filepath, 'r') as f:\n",
    "    for line in f:\n",
    "      start, end = line.strip().split(',')\n",
    "      clips.append((int(start), int(end)))\n",
    "  return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If clip range not given\n",
    "def detect_interesting_clips(video, fps, frame_thresh=100):\n",
    "  \"\"\"Detects interesting clips based on motion using frame differencing.\"\"\"\n",
    "  clips = []\n",
    "  prev_gray = cv2.cvtColor(video.read()[1], cv2.COLOR_BGR2GRAY)\n",
    "  while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "      break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_delta = cv2.absdiff(prev_gray, gray)\n",
    "    thresh = cv2.threshold(frame_delta, frame_thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    if len(cnts) > 0:\n",
    "      start_frame = video.get(cv2.CAP_PROP_POS_FRAMES) - 1\n",
    "      end_frame = video.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "      clips.append((start_frame / fps, end_frame / fps))\n",
    "    prev_gray = gray\n",
    "  return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short Video Creation\n",
    "def create_short_video(video, clips, music_path, fps=30):\n",
    "  \"\"\"Creates a short video with transitions and text overlays.\"\"\"\n",
    "  output_video = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (480, 864))  # Adjust resolution if needed\n",
    "  music = cv2.VideoCapture(music_path)\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "  for i, clip in enumerate(clips):\n",
    "    start_frame, end_frame = clip\n",
    "    start_frame = int(start_frame * fps)\n",
    "    end_frame = int(end_frame * fps)\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    text = f\"Clip {i+1}\"  # Example text overlay\n",
    "    text_size, _ = cv2.getTextSize(text, font, 1, 2)\n",
    "    text_pos = (10, text_size[1] + 10)\n",
    "\n",
    "    while video.get(cv2.CAP_PROP_POS_FRAMES) <= end_frame:\n",
    "      ret, frame = video.read()\n",
    "      if not ret:\n",
    "        break\n",
    "      # Resize frame to fit within 9:16 aspect ratio while maintaining content\n",
    "      frame = resize_and_crop(frame, (480, 864))\n",
    "      # Add text overlay at specific position\n",
    "      cv2.putText(frame, text, text_pos, font, 1, (255, 255, 255), 2)\n",
    "\n",
    "      ret, music_frame = music.read()\n",
    "      if ret:\n",
    "        # Add logic to synchronize transitions with music rhythm (e.g., using audio analysis libraries)\n",
    "        frame = add_transition(frame, music_frame, effect=\"cut\")  # Replace with chosen transition\n",
    "      else:\n",
    "        # Handle cases where music ends before video clips\n",
    "        pass\n",
    "\n",
    "      cv2.imshow('Output', frame)\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "  output_video.release()\n",
    "  music.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_crop(frame, target_size):\n",
    "  \"\"\"Resizes and crops a frame to fit within the target size while maintaining content.\n",
    "\n",
    "  Args:\n",
    "      frame: The input frame as a NumPy array.\n",
    "      target_size: A tuple representing the desired width and height of the output frame.\n",
    "\n",
    "  Returns:\n",
    "      A resized and cropped frame as a NumPy array.\n",
    "  \"\"\"\n",
    "  frame_height, frame_width, _ = frame.shape\n",
    "  target_height, target_width = target_size\n",
    "\n",
    "  # Calculate aspect ratios\n",
    "  frame_aspect_ratio = frame_width / frame_height\n",
    "  target_aspect_ratio = target_width / target_height\n",
    "\n",
    "  # Determine crop based on aspect ratio differences\n",
    "  if frame_aspect_ratio > target_aspect_ratio:\n",
    "    # Crop width\n",
    "    crop_width = int((frame_width - target_width * frame_aspect_ratio) / 2)\n",
    "    return cv2.resize(frame[:, crop_width:-crop_width], target_size)\n",
    "  else:\n",
    "    # Crop height\n",
    "    crop_height = int((frame_height - target_height / frame_aspect_ratio) / 2)\n",
    "    return cv2.resize(frame[crop_height:-crop_height, :], target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition(clip1, clip2, effect=\"cut\", num_frames=10):\n",
    "  \"\"\"Applies a transition effect between two video clips.\n",
    "\n",
    "  Args:\n",
    "      clip1: The first video clip as a NumPy array.\n",
    "      clip2: The second video clip as a NumPy array.\n",
    "      effect: The type of transition effect (e.g., \"cut\", \"dissolve\", \"wipe\").\n",
    "      num_frames: Number of frames to use for the transition (optional).\n",
    "\n",
    "  Returns:\n",
    "      A single video clip with the applied transition between the two input clips.\n",
    "  \"\"\"\n",
    "  if effect == \"cut\":\n",
    "    return np.concatenate((clip1, clip2), axis=0)\n",
    "  elif effect == \"dissolve\":\n",
    "    # Implement logic for dissolve transition using alpha blending (example)\n",
    "    transition_frames = []\n",
    "    for i in range(num_frames):\n",
    "      alpha = i / (num_frames - 1)\n",
    "      frame = cv2.addWeighted(clip1, 1 - alpha, clip2, alpha, 0)\n",
    "      transition_frames.append(frame)\n",
    "    return np.concatenate(transition_frames + clip2[num_frames:], axis=0)\n",
    "  # Add similar logic for other effects like wipe\n",
    "  else:\n",
    "    return clip1  # Handle unsupported effects gracefully (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalization\n",
    "def finalize_and_export(video_path, audio_path, output_path):\n",
    "  \"\"\"Combines audio and video, and exports the final short video.\"\"\"\n",
    "  # Use libraries like moviepy to combine audio and video streams\n",
    "  # Export the final video in the desired format (e.g., MP4)\n",
    "  video_clip = VideoFileClip(video_path).subclip(0, 30)  # Limit video to 30 seconds\n",
    "  audio_clip = AudioFileClip(audio_path)\n",
    "  final_clip = video_clip.set_audio(audio_clip)\n",
    "  final_clip.write_videofile(output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "  video_url = \"rocket_video.mp4\"  # Replace with actual URL or file path\n",
    "  music_path = \"music.mp3\"  # Replace with music file path\n",
    "  clips = [(5, 9), (15, 20), (35, 40)] #get_predefined_clips(\"clip_timings.txt\")  # Or use detect_interesting_clips()\n",
    "\n",
    "  video, fps, _ = download_and_analyze(video_url)\n",
    "  create_short_video(video, clips, music_path, fps)\n",
    "  finalize_and_export(\"output.mp4\", music_path, \"final_short_video.mp4\")\n",
    "\n",
    "  video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
